# What's AI ML and DL?
## Artificial Intelligence (AI)
AI คือศาสตร์ของการทำให้บางสิ่งบางอย่างฉลาดมากขึ้น อธิบายให้เห็นภาพคือ **เครื่องจักรที่มีความฉลาดเหมือนมนุษย์** และสามารถทำงานแทนมนุษย์ได้ โดย AI ที่ได้รับความนิยมในปัจจุบันเป็นส่วนหนึ่งของ **narrow AI** - คือ**ระบบที่สามารถทำ 1 สิ่ง หรือบางสิ่งบางอย่างในจำนวนไม่มากได้ดีหรือดีกว่ามนุษย์ทำเอง**

สิ่งที่ AI สามารถทำได้ปัจจุบัน เช่น
- **Object recognition**
- **Speech recognition / sound detection**
- **Natural Language Processing** / Sentiment analysis
- **Creative** (เช่น Style Transfer - เรียนรู้ที่จะวาดรูปภาพที่กำหนดให้ผสมภาพวาดอีกสไตล์ที่กำหนดให้ได้)
- **Prediction** - ให้ข้อมูลขาเข้าไปแล้วทำนายผลที่จะเกิดขึ้น
- **Translation**
- **Restoration / Transformation** - เช่น การหาว่าในรูปควรจะมีอะไร หรือการวาดใบหน้าคนโดยใช้ข้อมูลรูปที่มีอยู่

## Machine Learning (ML)
มีความหมายว่า **วิธีการสร้าง AI ผ่านระบบที่สามารถเรียนรู้ได้จากข้อมูล เรียนรู้ด้วยการหารูปแบบของชุดข้อมูลที่ป้อนเข้าไป** 

ML จะใกล้เคียงกับ**การสอนคอมพิวเตอร์ให้จดจำ และแยกแยะรูปแบบของข้อมูลได้ มากกว่าการเขียนโปรแกรมด้วยคำสั่งที่เจาะจง** อธิบายเพิ่มคือ ML จะสร้างอัลกอริทึม (ชุดชองกฏเกณฑ์) ที่เรียนรู้จากฟังก์ชั่นที่มีความซับซ้อน (รูปแบบ) จากข้อมูลที่ป้อนเข้าไปและทำนายผลออกมาก โดยอยู่ใน AI ประเภท narrow AI

ML นั้นเปรียบเหมือนการเลี้ยงเด็กเลย
1. มันต้องการข้อมูลเพื่อเรียนรู้
2. มันเรียนรู้รูปแบบของข้อมูลจากข้อมูลที่ป้อนเข้ามา
3. มันจะแยกประเภทของข้อมูลที่ไม่เคยพบมาก่อนอัตโนมัติเพื่อที่จะสามารถทำนายผลได้ดีมากยิ่งขึ้น

ระบบที่ผ่านการฝึกมาเหล่านี้**สามารถนำมาประยุกต์ใช้งานได้ในหัวข้ออื่น ๆ** ด้วยชุดคำสั่งเดียวกัน เช่น การตรวจจับสิ่งของประเภทอื่น ๆ จากข้อมูลใหม่ เป็นต้น

## Deep Learning (DL)
**เป็นเทคนิคสำหรับการทำ ML ให้ได้ประสิทธิภาพมากขึ้น**

หนึ่งใน DL เทคนิคคือ **deep neural networks (DNNs) - คือโครงสร้างของโค้ดถูกเขียนออกมาให้มีลักษณะคล้ายสมองของมนุษย์ มีการเรียนรู้รูปแบบของรูปแบบที่เกิดขึ้น** อ่านแล้วงงใช่ไหม ไม่ต้องตกใจผมยังงงตัวเองเลย

## สรุป
3 อย่างนี้เกี่ยวข้องกันยังไง - พูดง่าย ๆ คือแต่ละอันเป็น subset ย่อยของอีกอันดังแสดงในรูปด้านล่าง DL ทำให้ทำ ML ได้ดีขึ้นซึ่งส่งผลให้ AI มีประสิทธิภาพที่ดีขึ้นนั้นเอง

![[../_assets/machine_learning/intro_ML_DL_for_AI.png]]

# How to choose data to train ML?
## Features / Attributes
จุดเด่น (Features) หรือลักษณะ (Attributes) ของข้อมูลมักจะถูกนำมาฝึกฝนระบบ ML เพราะปกติแล้วเรามักแบ่งประเภทของสิ่งของด้วย features ของมัน เช่น รูปร่าง สี น้ำหนัก เป็นต้น 

ยกตัวอย่างเป็นการแยกประเภทของผลไม้ ถ้าเราจะแยกประเภทของมันเราจะแยกด้วยสี แต่ถ้าเป็นระบบ ML **การแยกประเภทด้วย Feature เพียงอันเดียวจะทำให้ไม่ได้ผลลัพธ์ที่ดี** ดังนั้นเราจะดึง feature หลัก ๆ ที่ต่างกันออกมา 2 อย่างคือ สี และน้ำหนัก โดยระบบจะทำการพล็อตข้อมูลออกมาอยู่รูปกราฟ **2 Features ระบบก็จะพล็อตกราฟออกมาอยู่ 2 มิติ**ดังรูป (น้ำหนัก และสีสามารถทำให้อยู่ในรูปของตัวเลขได้จึงถูกทำออกมาอยู่ในรูปของกราฟ) 

![[../_assets/machine_learning/features_1.png|500]]

จากรูปจะเห็นว่าระบบ ML จะสามารถเรียนรู้จากข้อมูล และทำการสร้างเส้นปะสีเหลืองที่นำมาเป็นเกณฑ์ในการแบ่งประเภทของผลไม้ได้ โดย**เส้นที่สร้างขึ้นนี้สามารถนำมาใช้แบ่งแยกประเภทได้เมื่อเราทำการป้อนข้อมูลใหม่เข้าไป** (หากอยู่ด้านบนเป็นส้ม และด้านล่างเป็นแอปเปิล)

การเลือกข้อมูลที่นำมาฝึกระบบก็มีความสำคัญเช่นกัน **ข้อมูลที่ฝึกยิ่งมีคุณภาพเท่าไหรระบบที่เราฝึกก็จะมีคุณภาพเท่านั้น** เช่น แทนที่เราจะเลือกสี และน้ำหนักของผลไม้ แต่เราไปเลือกเป็นจำนวนเมล็ด และความสุกของผลไม้แทน ซึ่งทั้ง 2 feature ของส้ม และแอปเปิ้ลแทบไม่ต่างกันเลยจะทำให้ระบบไม่สามารถเรียนรู้อะไรได้จากข้อมูลชุดนี้เลยดังรูป

![[../_assets/machine_learning/features_2.png|500]]

ในความเป็นจริงแล้ว feature ที่ดีนั้นไม่ได้หาได้ง่าย ๆ เหมือนตัวอย่าง เราต้องผ่านประสบการณ์ และฝึกฝนมากเพื่อที่เราจะสามารถค้นหา feature ที่เหมาะสมกับการนำมาฝึกระบบ

##  Non trivial data
จากตัวอย่างเราจะพล็อตกราฟด้วย 2 feature หรือ 2 มิติ เราสามารถเพิ่มความแม่นยำของการทำนายได้ด้วยการใช้ 3 feature เราสามารถพล็อตข้อมูลในกราฟ 3 มิติ เราจะสามารถแบ่งกลุ่มของข้อมูลได้ด้วยระนาบ 2 มิติ ดังรูป

![[../_assets/machine_learning/non_trivial_data_1.png|500]]

**การเพิ่มมิติมักสามารถช่วยให้สามารถแยกชุดข้อมูลได้ดียิ่งขึ้น แต่การถ้ามีมากเกินไปก็จะทำให้ไม่สามารถนำกลุ่มข้อมูลที่พบไปแยกชุดได้ดีเท่าที่ควร** 

## Data hunting
หลังจากที่รู้ว่าต้องใช้ feature อะไร **สิ่งที่ท้าทายที่สุดคือการหาข้อมูลที่มีความเป็นกลางให้มากพอสำหรับการฝึกระบบ**ที่มี feature ที่ต้องการดังกล่าว (ขึ้นอยู่กับ algorithm ของระบบด้วย)

หากต้องการแยกประเภทผลไม้ก็ควรมีรูปผลไม้อย่างต่ำ 10,000 รูปเพื่อให้ได้ผลลัพธ์ที่พอใช้ได้

ข้อมูลไม่ได้มีแค่รูปภาพ อาจะเป็นตารางที่มีข้อมูลมากมาย ตัวอักษร การเก็บค่าของเซนเซอร์ ตัวอย่างเสียง และอีกหลายแบบขึ้นอยู่กับสิ่งที่คุณต้องการแยกประเภท

## ระบบ ML ไม่สามารถทำนายผลบางสิ่งที่ไม่เคยเจอได้
เช่น ระบบของเราแยกผลไม้โดยใช้ feature ดังนี้

**Color, Weight, Fruit**
Orange, 300g, Orange
Red, 200g, Apple

แต่ถ้าเราใส่ข้อมูลที่ไม่รู้จักเข้าไป เช่น Green, 200 g, Mango ระบบก็จะทำนายผลเป็นส้ม เพราะระบบรู้จักแค่ส้มกับแอปเปิ้ล และคำตอบที่ใกล้เคียงมะม่วงที่สุดก็คือแอปเปิ้ล
# Great overview for two topic above
[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/nKW8Ndu7Mjw/0.jpg)](https://www.youtube.com/watch?v=nKW8Ndu7Mjw)

# How ML systems are trained (Learning Style)
## Supervised Learning
คือระบบที่**ถูกฝึกด้วยข้อมูลที่มีการบอกว่าข้อมูลแต่ละกลุ่มคืออะไร** เราบอกระบบเบื้องต้นว่าข้อมูลแต่ละกลุ่มคืออะไร เช่น

**Colour, Weight, Lebel**
Red, 200g, Apple
Orange, 300g, Orange
Green, 150g, Apple
...

ให้ข้อมูลไป 2 ประเภท (สี และน้ำหนัก) เราบอกระบบว่าด้วยข้อมูลชุดไหนคือจัดกลุ่มยังไง (แอปเปิ้ล ส้ม) - **supervision** ระบบจะต้องใช้ข้อมูลชุดนี้ในการทำนายผลข้อมูลที่ยังไม่เคยเจอ

## Unsupervised Learning
**ระบบต้องเรียนรู้จากชุดข้อมูลที่ไม่มีการจัดชื่อกลุ่มข้อมูลไว้ให้** ยกตัวอย่างดังรูป

![[../_assets/machine_learning/unsupervised_learning.png|500]]

จากรูปจะมีข้อมูลกระจัดกระจายออกเป็น 3 กลุ่มใหญ่ ๆ ระบบต้องรู้ด้วยตัวเองว่ามีข้อมูลอยู่ 3 กลุ่มและจัดกลุ่มเอง

ลำดับของกลุ่มเราจะไม่มีทางรู้ก่อนได้เลย เพราะระบบจะเรียนรู้ด้วยตัวมันเอง และบางครั้งชุดข้อมูลที่ได้จะไม่สามารถจัดกลุ่มได้ง่ายเหมือนดังรูป
## Reinforment Learning
**ระบบเรียนรู้ผ่านการสุ่มคำตอบ และทำใหม่จนได้คำตอบที่น่าพึ่งพอใจ (trial-and-error) ผ่านระบบการให้รางวัล และบทลงโทษ**

**ระบบจะเรียนรู้ผ่านการทำไปวนไปเรื่อย ๆ เมื่อระบบได้ผลลัพธ์ที่น่าพอใจเราจะให้รางวัล แต่เมื่อระบบได้ผลลัพธ์ที่ไม่น่าพอใจเราจะไม่ให้รางวัลกับระบบ หรือทำการลงโทษ** ระบบจะเรียรรู้ว่าอันไหนควรทำ และไม่ควรผ่านระบบนี้

เมื่อผ่านไปซักระยะหนึ่งระบบจะสามารถรู้ได้ว่าทำแบบไหนถึงได้ผลลัพธ์ที่ดีโดยไม่ต้องให้มนุษย์มาคอยบอก บางครั้งระบบจะสามารถทำได้ดีกว่ามนุษย์ด้วย เพราะระบบสามารถทำสิ่งที่มนุษย์ไม่คิดจะทำได้
# แล้วสรุประบบเรียนรู้ยังไง
## ได้หลายแบบมาก
มันมีหลายวิธีมากที่ระะบบสามารถที่จะลอง และเรียนรู้รูปแบบเพื่อที่จะแยกประเภทข้อมูล โดยผมจะอธิบายผ่านตัวอย่างเล็กน้อยต่อไปนี้ ตัวอย่างเหล่านี้จะช่วยในเสริมสร้างความเข้าใจ ในปัจจุบันการวิจัยล้ำสมัยมากมาย (บางครั้งก็ผสมสูตรหลายสูตร และแนวคิดที่แยบยลมากมายเกินกว่าที่เอกสารชุดนี้อธิบายไปมาก) ที่ยังใช้สูตรทางคณิตศาสตร์พื้นฐานในการหารูปแบบของข้อมูล

## ตัวอย่างที่ 1

![[../_assets/machine_learning/example_1.png|500]]

ยังจำสมัยเรียนได้ไหมที่เราจะพล็อตข้อมูลแล้วครูสั่งให้**วาดเส้นตรงให้ผ่านจุดมากที่สุด** เส้นตรงนี้แหละคือ**ระบบ ML อย่างง่าย**

**เราสามารถหาค่าของ x ผ่านค่า y ที่เรามีอยู่ได้** หรือแม้กระทั่งชุดข้อมูลที่เกินกว่าเส้นตรงที่เราขีด เราก็สามารถลากเส้นนี้ต่อไปจนถึงชุดข้อมูลใหม่เราได้ รูปแบบนี้เราเรียกว่า **regression** 

**ระบบสามารถคำนวณหาเส้นเหล่านี้ได้ด้วยตัวของมันเอง**


## ตัวอย่างที่ 2

![[../_assets/machine_learning/example_2.png|500]]

ในตัวอย่างนี้**เราสามารถแบ่งกลุ่มออกเป็น 2 กลุ่มด้วยเส้น** ด้วยการทำแบบนี้เราสามารถแบ่งกลุ่มของข้อมูลที่จะป้อนเข้ามาภายหลังได้ เช่น อยู่เหนือเส้นจะอยู่ในกลุ่มสีชมพู ต่ำกว่าเส้นจะอยู่ในกลุ่มสีฟ้า

อย่างที่ได้เห็นในรูปบางครั้งจะมี**ข้อมูลที่ผิดปกติ (outliners)** แต่ส่วนใหญ่มักระบบมักจะทำนายผลถูก

ในรูปเราใช้เส้นตรงในแบ่งกลุ่มแต่ในบางกรณีเราสามารถใช้เป็นรูปร่างที่มีความซับซ้อนกว่านี้ได้ เช่น สี่เหลี่ยมจตุรัส (quadratic)

## ตัวอย่างที่ 3

![[../_assets/machine_learning/example_3.png|500]]

อย่างในตัวอย่างนี้ระบบจะไม่ได้ใช้เส้นตรงในการแบ่งกลุ่มข้อมูล ระบบแบ่งกลุ่มผ่าน**วิธีสุ่มตัวอย่างข้อมูล และหาจุดของข้อมูลที่รู้ที่อยู่ใกล้เคียง (sampling x known points close by)** อธิบายคือสมมุติข้อมูลทึ่เราป้อนเพิ่มเข้าไปอยู่ตรงกลางรูป จุดที่อยู่ใกล้ชุดข้อมูลเรามากสุดคือจุดของกลุ่มสีฟ้า ดังนั้นชุดข้อมูลใหม่เราจะอยู่ในกลุ่มสีฟ้า โดยสีในพื้นหลังสามารถนำมาใช้แบ่งกลุ่มชุดของข้อมูลที่จะนำมาป้อนให้ระบบในอนาคตได้ วิธีการแบ่งกลุ่มข้อมูลแบบนี้เรียกว่า **k-nearest neighbour**


## Neural Networks
**หัวสมองของมนุษย์ประกอบไปด้วย 86 พันล้านเซลล์ประสาท (neuron) ที่เชื่อมต่อระหว่างกัน** ทุกเซลล์ประสาทสามารถรับรู้ถึงการกระตุ้น และส่งข้อมูลไปให้เซลล์อื่น ๆ

เช่น เมื่อเราจะแยกระหว่างสุนัข และแมว เราจะสังเกตุจากรูปร่างลักษณะ (สีขน ตา) ผ่านตา ฟังเสียงของมันผ่านหู เมื่อนำสิ่งที่เราสังเกตุได้เหล่านี้มารวมกันสมองของคุณจะบอกว่ามันคือสัตว์ชนิดไหน

ในระบบ ML artificia; neural networks (ที่ออกแบบเลียนสมองของมนุษย์) ถูกใช้งานเพื่อคำนวณหาความเป็นไปได้โดย feature ที่ได้รับการฝคกฝนมา

## Deep Neural Networks (DNN)
ประกอบไปด้วยชั้นการประมวลผลที่ถูกซ้อนไว้ (hidden layer) ระหว่างชั้นที่มีการรับข้อมูล และชั้นของผลลัพธ์ ทุก ๆ ชั้นสามารถเรียนรู้จากชั้นก่อนหน้าได้ โดยชั้นประมสลผลเหล่านี้จะมีมิติของข้อมูลต่ำเพื่อจัดกลุ่มของข้อมูลได้ง่ายขึ้น และไม่เฉพาะเจาะจงเกินไป โดยชั้นเรานี้จะสามารถเรียนรู้ feature ใน feature ที่มีความละเอียดมากขึ้นได้

![[../_assets/machine_learning/deep_neural_networks.png]]

จากรูปจะเห็นได้ว่าเส้นขอบหลาย ๆ เส้นสามารถนำมารวมกันกลายเป็นส่วนหนึ่งของใบหน้า และชุดข้อมูลส่วนหนึ่งของใบหน้าก็สามารถนำมารวมกันกลายเป็นใบหน้ามนุษย์ได้

### ศึกษาเพื่มเติม

[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/aircAruvnKk/0.jpg)](https://www.youtube.com/watch?v=aircAruvnKk)

### Convolutional Neural Networks

[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/FmpDIaiMIeA/0.jpg)](https://www.youtube.com/watch?v=FmpDIaiMIeA)

# Types of ML output
## Common ML Output types
- **Regression** ทำนายตัวเลข เช่น ราคาของอสังหาริมทรัพย์ 
- **Classification** หนึ่งในชื่อกลุ่มของข้อมูล เช่น แอปเปิ้ล ส้ม มะม่วง เป็นต้น
- **Clustering** สิ่งที่ใกล้เคียงกับตัวอย่าง เช่น เพลงที่ลักษณะใกล้เคียงกับเพลงที่ฟังอยู่ 
- **Sequence Prediction** อะไรจะเกิดขึ้น เช่น ถ้าไม่ทำอะไรเลย -> ก็ไม่ได้อะไรกลับมาเลย
## Continuous Output
หมายถึง**ผลลัพธ์ของระบบเป็นเลขทศนิยม**

เราให้ข้อมูลเข้าไปแล้วได้ผลลัพธ์เป็นเลขทศนิยม เช่น เราใส่น้ำหนักของส้มเข้าไป 200g แล้วได้ผลลัพธ์ออกมาเป็นรัศมีของส้ม 4.2 นิ้ว และนี้เป็นสิ่งที่ระบบ ML พยายามจะทำนาย **Linear regression** เป็นตัวอย่างที่ดี

![[../_assets/machine_learning/continuous_output.gif|500]]

จากรูปจะเห็นว่าระบบพยายามที่จะพยายามขีดเส้นตรงห้ผ่านข้อมูลมากที่สุด เพื่อที่เราจะสามารถทำนายผลหา y เมื่อเรามีค่า x ได้
## Classification
เกี่ยวกับการจัดกลุ่มให้กับข้อมูลที่ป้อนเข้าไป โดยข้อมูลไม่ได้เกี่ยวข้องกันโดยตรง เช่น ข้อมูลที่ป้อนเข้ามามีขน ลักษณะอุ้งเท้า และหนวด ผลลัพธ์ที่ได้คือแมว

![[../_assets/machine_learning/classification.gif|500]]

ผลลัพธ์ที่ได้ออกมาจะเป็นชื่อที่บ่งบอกว่ากลุ่มข้อมูลคืออะไร

## Probability Estimation
หมายถึง**ผลลัพธ์ของระบบ ML คือเลขทศนิยมมีค่าระหว่าง 0 ถึง 1** ซึ่งบ่งบอกถึงโอกาสการเกิดของเหตุการณ์ที่เรากำหนด เช่น 0.831 -> 83.1%

![[../_assets/machine_learning/probability_estimation.gif|500]]

เช่น ระบบทำนายโอกาสการทำข้อสอบผ่านของนักศึกษา ผ่านชุดข้อมูลพฤติกรรมของนักศึกษาที่เราป้อนเข้าไป แล้วได้ผลลัพธ์ออกมาอยู่ที่ 89.4% เราสามารถนำข้อมูลนี้ไปใช้ประโยชน์ต่อได้
## ใช้ประโยชน์จากผลลัพธ์ที่ได้
หลังจากที่ได้ผลลัพธ์ในรูปแบบต่าง ๆ regression probability หรือ classifacation มันขึ้นอยู่กับ programmer แล้วว่าจะสามารถทำประโยชน์อะไรได้ หรือได้ความรู้อะไรจากมัน

ถ้าผลลัพธ์ออกมาอยู่ที่ 80% แล้วอาจจะชัวแล้วว่าควรจะทำอะไรต่อ แต่หากได้ 60% แล้วอาจจะรอให้ได้ความเป็นไปได้มราใสกกว่านี้เพื่อความชัวร์
# Types of ML algorithms
โดยเราจะแบ่งกลุ่มตามลักษณะการทำงานของ algorithm แต่ก็ยังมี algorithm บางอันที่ไม่สามารถถูกจัดกลุ่มได้ เพราะมีหลักการทำงานคล้ายกับ 2 กลุ่มใหญ่ ๆ ที่เราได้แบ่งกัน
## Regression

![[../_assets/machine_learning/regression-algorithms.png|250]]

Regression หรือการถดถอยคือการสร้างความสัมพันธ์ระหว่างตัวแปรที่จะถูกทดลองและทำซ้ำจนได้ค่าที่น่าพึงพอใจโดยวัดผลจากเปอร์เซ็นต์ความผิดพลาดของค่าที่ถูกทำนายจากโมเดลและค่าจริงของข้อมูล

Algorithm ที่ได้รับความนิยมในกลุ่มนี้คือ
### Ordinary Least Squares Regression (OLSR)
### Linear Regression
หลักการคือการเส้นตรงที่ผ่านจุดข้อมูลมากที่สุด เมื่อป้อนข้อมูลให้ระบบแล้ว ระบบจะสร้างเส้นตรงดังกล่าวอัตโนมัติ

![[../_assets/machine_learning/linear-regression-1.jpg|500]]

เส้นตรงนี้สามารถหาได้จากสมการ $y = mx+c$
m คือค่าความชัน คำนวณได้จากสมการ $m = \frac{y_{2}-y_{1}}{x_{2}-x_{1}}$
c คือค่า y ที่เส้นตรงเราไปตัดแกน y

หลังจากที่โมเดลเราสร้างเส้นได้ ระบบจะใช้เส้นนี้ในการทำนายผลลัพธ์
ในตัวอย่างด้านบนเป็นแบบ 2 มิติ ในความเป็นจริงนั้นเส้นที่โมเดลเราสร้างขึ้นสามารถทอดข้ามหลายมิติได้ และจะมีค่า $m$ หลายค่า
### Logistic Regression
### Stepwise Regression
### Multivariate Adaptive Regression Splines (MARS)
### Locally Estimated Scatterplot Smoothing (LOESS)

## Intance-based

![[../_assets/machine_learning/Instance-based-algorithms.png|250]]

การใช้ algorithm นี้นั้นหมายความว่าชุดตัวอย่างข้อมูลที่นำมาฝึกโมเดลจะต้องมีความสำคัญ หรือมีความจำเป็นต่อโมเดล (จุดข้อมูลทุกจุดต้องนำมาใช้ในการคำนวณ ไม่เหมือนตระกูล regression ที่เหมือนหาสมการได้แล้วข้อมูลที่ใช้ในการฝึกก็ไม่จำเป็นอีกต่อไป) 

วิธีการนี้จะทำให้เราเหมือนได้สร้าง database ของข้อมูลที่ใช้ฝึกขึ้นมา และต้องเอาข้อมูลใหม่มาเปรียบเทียบเพื่อหาว่าใกล้เคียงกับข้อมูลที่ใช้ฝึกข้อมูลไหนมากที่สุดเพื่อทำนายผลลัพธ์ **โฟกัสที่การเก็บข้อมูล และวัดระยะห่างระหว่างจุดข้อมูล**

Algorithm ที่ได้รับความนิยมในกลุ่มนี้คือ
### K-Nearest Neighbor (kNN)
ถ้าให้อธิบายสั้นๆ KNN จะทำงานโดยค้นหาจุดที่ใกล้เคียงจำนวน K จุด ณ บริเวณรอบ ๆ จุดข้อมูลที่เราต้องการจัดกลุ่ม และเลือกกลุ่มที่ตามลักษณะ และจำนวนจุดที่ใกล้เคียง เช่น เรากำหนดให้ระบบมี K=3 แล้วจุดที่เราสนใจมีจุดสีฟ้า 1 จุด สีเขียว 2 จุด จุดที่เราสนใจจะถูกจัดอยู่ในกลุ่มสีเขียว

![[../_assets/machine_learning/k-nearest-neighbours-1.png|500]]

แต่วิธีนี้ก็มี**ข้อเสีย**ใหญ่ ๆ เลยคือ**เวลาที่ใช้ในการฝึก และทำนายผลนาน** เพราะ alogorithm นี้จะหาระยะห่างระหว่างจุดข้อมูล และต้องหาทุก ๆ จุดข้อมูลในชุดข้อมูลที่เราป้อนเข้ามาฝึกดังนั้นจึงเกิดคำนวณขึ้นเยอะมาก ๆ

และอีกข้อเสียคือ**กินทรัพยาการเครื่องมาก** เพราะทุกครั้งที่มันทำงานจะต้องดึงข้อมูลทั้งหมดมาทำการทำนาย สามารถแก้ด้วยการทำ batch load ข้อมูลเราได้แต่มันกินเวลาค่อนข้างมากในการทำ

สรุปแล้ววิธี KNN จะ**เหมาะกับการแบ่งกลุ่มที่มีข้อมูลน้อย และมี feature ไม่มาก**
### Learning Vector Quantization (LVQ)
### Self-Organizing Map (SOM)
### Locally Weighted Learning (LWL)
### Support Vector Machines (SVM)
ทำงานโดยการแบ่งข้อมูลออกเป็นหลาย ๆ กลุ่มด้วย **hyper-plane** (ถ้าเป็น 2D จะเป็นเส้น ถ้าเป็น 3D จะเป็นระนาบ ถ้ามากกว่า 3D จะเรียกว่า hyper-plane)

![[../_assets/machine_learning/support-vector-machines-1.png|500]]

ตอนที่สร้าง hyper-plane เราต้องเลือกจุดที่อยู่ใกล้ hyper-plane มากที่สุดของแต่ละกลุ่มมา (ในรูปจะมี 5 จุด) จุดที่เราเลือกมาจะเรียกว่า **support vectors** จุดเหล่านี้ต้องอยู่ใกล้ และมีระยะห่างจาก hyper-plane เท่ากัน 

จากหลักการที่เราอธิบายไปข้างต้นจะทำให้ทราบได้ว่าเราสามารถสร้าง hyper-plane ได้มากกว่า 1 ที่ แล้วเราจะรู้ได้อย่างไรว่า hyper-plane ไหนดีที่สุด คำตอบคือ **margin**

![[../_assets/machine_learning/support-vector-machines-2.jpg|500]]

margin คือระยะห่างจาก hyper-plane ถึง support vector ยิ่งมีระยะห่างมากเท่าไหรยิ่งทำให้การแบ่งกลุ่มดียิ่งขึ้น แต่ในความเป็นจริงแล้วคงเป็นไปได้ยากถ้าจะไม่ให้มีจุดข้อมูลเข้าไปใน margin เราเลย แต่เราสามารถปรับแต่ง **soft & hard margin**

![[../_assets/machine_learning/support-vector-machines-3.png|500]]

hard margin คือ margin ที่ไม่อนุญาติให้มีจุดข้อมูลใด ๆ อยู่ในนั้นเลย แต่ soft margin นั้นคือการที่เรากำหนดจุดของข้อมูลมากที่สุดที่สามารถเข้าไปอยู่ใน soft margin เราได้ ถ้าเราใช้ hard margin นอกจากที่จะทำให้สร้าง hyper-plane ได้ยากแล้วยังส่งผลให้คุณภาพของการแบ่งกลุ่มแย่ลงด้วย (margin แคบ)

แล้วถ้าข้อมูลเราทับกันจนไม่สามารถสร้าง hyper-plane ได้จะทำยังไง เราลองมาทำความรู้จักกับ **kernel** กัน

![[../_assets/machine_learning/support-vector-machines-4.png|500]]

kernel คือฟังก์ชันที่รับค่าจาก feature ที่เราป้อนไปเพื่อคำนวณ แล้วนำผลลัพธ์ที่ได้สร้างเป็นอีก feature เพื่อให้เห็นภาพขอยกตัวอย่างเป็นข้อมูลใน 2 มิติ ตอนแรกข้อมูลเราจะมี x, y เรานำข้อมูลเหล่านี้ไปผ่าน kernel -> $f(x, y) = z$ เราจะได้ผลลัพธ์มาเป็น z ซึ่งจะเป็นค่าที่บอกตำแหน่งของข้อมูลเราใน 3 มิติ ดูรูปประกอบ

รูปแบบ kernel ที่นิยมใช้ เช่น
- Linear
- Polynomial
- Circular
- Hyperbolic Tangent (Sigmoid)
## Decision Trees
## Batesian
## Clustering (Unsupervised)

![[../_assets/machine_learning/clustering-algorithms.png|250]]

โดยทั่วไปแล้วจะจัดกลุ่มโดยสร้างด้วย centroid-based และ hierarchal 

Algorithm ที่ได้รับความนิยมในกลุ่มนี้คือ
### k-Means
แบ่งกลุ่มตามขั้นตอนด้านล่าง กล่าวโดยสรุปวิธีนี้จะแบ่งพื้นที่ออกเป็นโซน ๆ สำหรับแบ่งกลุ่ม ข้อมูลตกอยู่ในโซนไหนจะถูกจัดให้อยู่ในกลุ่มนั้น
1. กำหนดค่า K เพื่อสุ่มสร้าง centroid K จุดบนกราฟเรา
2. จัดให้จุดข้อมูลที่อยู่ใกล้ centroid มากที่สุด อยู่ในกลุ่มเดียวกับ centroid นั้น ๆ
3. หา center of mass ของกลุ่มที่เราจัด จากนั้นย้ายจุด centroid เราไปที่จุดนั้น
4. จัดกลุ่มให้กับจุดข้อมูลใหม่อีกครั้ง
5. ทำขั้นตอน 3-4 ไปจนกว่าจะไม่มีจุดไหนเปลี่ยนกลุ่มอีก

![[../_assets/machine_learning/k-means_convergence.gif|500]]
### k-Medians
### Expectation Maximisation (EM)
### Hierarchical Clustering
## Association Rules
## Artificial Neural Networks
## Deep Learning
## Dimensionality Reduction
## Ensemble
[A Tour of Machine Learning Algorithms](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)
# Credit
[Jason’s ML 101 slides](https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/mobilepresent#slide=id.g168a3288f7_0_58)
ผมได้นำเอกสารชุดนี้มาเขียนให้เข้าใจในภาษาของตัวเองหากอ่านแล้วไม่เข้าใจสามารถไปอ่านต้นฉบับได้เลยครับ